\section{Automata Theory}

Automata theory is concerned with the study of abstract automata and computational models.
The aim is to study their essential properties and which types of computational problems can be solved by using them.

\subsection{Basic Definitions}

\begin{definition}
    The set of all finite sequences of an alphabet $\Sigma$ is written as $\Sigma^\ast$.
    It is formally defned as
    $\Sigma^\ast = \cup_{i=0}^{\inf} \{c_1 c_2 \ldots c_i \mid \forall 1 \le i \le n: c_i \in \Sigma \} $
    A language is a subset of $\Sigma^\ast$.
\end{definition}

The empty sequence (containing no symbols at a all) is denoted by $\epsilon$.

\subsection{Deterministic Finite Automata}

Deterministic finite automata (DFAs) can be thought of as graphs with labeled vertices and edges.

\begin{definition}
    A DFA can be defined using the following five components:

    \begin{itemize}
        \item A set of vertices $Q_D$, called states.
        As implied by the term DFA, this set has to be finite.
        \item A set of labels $\Sigma_D$ on the vertices which is called the alphabet of input symbols.
        It has to be finite as well.
        \item An ``initial'' state $s_D \in Q_D$.
        \item A number of states $F_D \subseteq Q_D$ called accepting states.
        \item A set of directed edges called transitions.
        Each transition is labelled with one input symbol.
        Furthermore, for each input symbol there is exactly one transition labelled with
        the symbol between each pair of states.
        Because of this, this set can be represented by a total function
        $\delta_D : Q_D \times \Sigma_N \rightarrow Q_D$ which associates a successor state to
        every pair of state and input symbol.
    \end{itemize}
\end{definition}

DFAs are chiefly used to represent transition systems.
A system modeled by the automaton is thought as always being in one of the states contained in the automata.
When the system receives an input, a transition to another state is possible.

For certain classes of languages, a DFA can be used to decide whether a specific word $w$ is contained in a language $L$.
This is done by first constructing an appropriate automaton $M$ for the language.
Then, the transition system is initialized to be at the initial state $s_{M}$.
Then, the word $w$ is treated as a sequence of input symbols $c_1 c_2 \ldots c_n$.
For each input symbol, the state transition $\delta_{M}(q, c)$ matching the current state $q$ and input symbol $c$ is followed.
If the system reaches one of the accepting states and there are no more input symbols left, then the
automaton is said to accept the input.

The following lines formally describe this procedure:
\begin{align}
    w \in L \Leftrightarrow \hat\delta_{M_L}(s_{M_L}, w) \in F_{M_L}
\end{align}

\begin{definition}
    $\hat\delta$ is the transition function of the automaton $M$, extended to words.
    This is done by using induction over the length of the input word.
    \begin{align}
        \hat\delta_M(q, \epsilon) &= q\\
        \hat\delta_M(q, c w) &= \hat\delta_M(\delta_M(q, c), w)
    \end{align}
\end{definition}

\begin{definition}
    The set of words accepted by starting from a state $q$ is said to be the language of $q$.
    The language accepted by the initial state of an automata $M$ is the language of $M$.

    \begin{align}
        \Lang{q} &= \{ w \in \Sigma^\ast \mid \hat\delta_M(q, w) \in F_M \}\\
        \Lang{M} &= \Lang{s_M}
    \end{align}
\end{definition}

\subsection{Nondeterministic Finite Automata}

Nondeterministic finite automata (NFAs) are defined almost the same way as DFAs.
There are two differences: There can be more than one initial state.
Also, multiple transitions carrying the same input symbol can connect a state to different
successor states.

\begin{definition}
    A DFA can be defined using the following five components:

    \begin{itemize}
        \item A set of vertices $Q_N$, called states.
        Also for NFAs this set has to be finite.
        \item A set of labels $\Sigma_N$ on the vertices which is called the alphabet of input symbols.
        It has to be finite as well.
        \item A set of vertices called ``initial'' states $S_N \subseteq Q_N$.
        \item A number of states $F_N \subseteq Q_N$ called accepting states.
        \item A set of directed edges called transitions.
        Each transition is labelled with one input symbol.
        This set can be represented by a total function
        $\Delta_N : Q_N \times \Sigma_N \rightarrow \mathcal{P}(Q_N)$ which
        associates a set of successor states to every pair of states and input symbols.
    \end{itemize}
\end{definition}

Also NFAs can be used to decide whether a word $w$ is decided in a language $L$.
The idea is the same as for DFAs: the word $w$ is treated as a sequence of input symbols.
This sequence is then again used to traverse the graph from a starting state.
If the traversal ends in an accepting state then the word is said to be accepted.

NFAs complicate this procedure though because from every state more than one
transition, or no transition at all, is allowed to lead to successor states.
Also, there can be more than one initial states, or none at all.
Therefore it is in general not possible to know up front for a sequence of input symbols
a sequence of transitions which will lead to an accepting state.

The solution is to simulate all possible executions of the automaton.
This is done by extending the transition function to take a set of states as input.
The intuition is to compute the set of possible successor state for each encountered state and input symbol.
This reduces our problem to another set of states and a shorter word.

\begin{definition}
    The extended transition function $\hat\Delta$ takes a set of states and a
    word as input and inductively computes all states which can be reached
    after traversing the automaton as indicated by the word.

    \begin{align}
        \hat\Delta(R, \epsilon) &= R \\
        \hat\Delta(R, c w) &= \hat\Delta(\bigcup\limits_{r \in R} \Delta(r, c), w)
    \end{align}
\end{definition}

The function $\hat\Delta$ can now be used to determine whether a word is accepted by an NFA:

\begin{align}
    w \in L \Leftrightarrow \hat\Delta(S_{M_L}, w) \subseteq F_{M_L}
\end{align}

\begin{definition}
    Every NFA $N$ can be converted into a DFA $D_N$ as follows:
\end{definition}

\subsection{Regular Expressions}

Regular expressions are a formal language which is used to represent languages, that is, sets of strings.
Regular expressions are equivalent in expressive power to the DFAs and NFAs presented above,
but in many cases humans find them more pleasant to work with.

\begin{definition}
    The language $R_\Sigma$, the set of regular expressions over the alphabet $\Sigma$,
    is inductively defined as the smallest set satisfying the following rules:

    \begin{itemize}
        \item The empty set is a regular expression:
        $\emptyset \in R_\Sigma$.
        \item The empty string $\epsilon$ is a regular expression:
        $\epsilon \in R_\Sigma$.
        \item A character from $\Sigma$, like $a$, is a regular expression:
        $\forall c \in \Sigma: c \in R_\Sigma$.
        \item Two regular expressions, concatenated using the operator $\cdot$, is a regular expression:
        $\forall r, s \in R_\Sigma: r \cdot s \in R_\Sigma$.
        In most cases, the operator is omitted to make the regular expression more concise.
        \item Two regular expressions, combined using the operator $+$, form a regular expression:
        $\forall r, s \in R_\Sigma: r + s \in R_\Sigma$.
        \item An application of the postfix operator $\ast$ to a regular expression is a regular expression:
        $\forall r \in R_\Sigma: r^\ast \in R_\Sigma$.
        \item A regular expression, surrounded by $()$, is a regular expression:
        $\forall r \in R_\Sigma: (r) \in R_\Sigma$.
    \end{itemize}
\end{definition}

As with every formal language, a semantics is required for regular expressions to define their meaning.

\begin{definition}
    The following inductive definitions map regular expressions over an alphabet $\Sigma$ to languages:

    \begin{itemize}
        \item $\Lang{\emptyset} = \{\}$
        \item $\forall c \in \Sigma: \Lang{c} \coloneqq \{c\} $
        \item $\forall r, s \in R_\Sigma: \Lang{r \cdot s} \coloneqq \Lang{r} \Lang{s} = \{ u v \mid u \in \Lang{r}, v \in \Lang{s} \}$
        \item $\forall r, s \in R_\Sigma: \Lang{r + s} \coloneqq \Lang{r} \cup \Lang{s}$
        \item $\forall r \in R_\Sigma: \Lang{r^\ast} \coloneqq \Lang{r}^\ast = \bigcup\limits_{i=0}^{\inf} \Lang{r}^i$
    \end{itemize}
\end{definition}

\subsection{Derivatives of Regular Expressions}

Taking the Brzozowski derivative of regular expressions is an interesting operation which, among others, can be used
to implement regular expressions in software, and also to convert regular expressions into finite automata.
It can also be extended to other classes of formal languages~\cite{parsing-with-derivatives}.
The operation has similarities to taking the (partial) derivative of arithmetic expressions.

\begin{definition}
    The derivative of a regular expression $r$ w.r.t. a letter $c$ is
    the set of all words in $\Lang{r}$ which start with $c$:

    \begin{align}
        \Lang{D_c(r)} \coloneqq \{ w \mid c w \in \Lang{r} \}
    \end{align}
\end{definition}

It is possible to derive regular expressions by using an algorithm which operates on the syntactic level.
The idea is always the same, but there exist multiple variants of the algorithm.
These stem from the fact that care has to be taken to simplify intermediary results to ensure termination.
In the following the variant of the algorithm in~\cite{proof-pearl-regular-expression-equivalence} is presented.

\begin{definition}
    The derivative of a regular expression $r$ over the alphabet $\Sigma$
    can be computed by the following recursive algorithm:

    \begin{align}
        D_{c}(r) &\rightarrow
        \begin{cases}
            \emptyset                       & \text{if } r = \emptyset,\\
            \emptyset                       & \text{if } r = \epsilon,\\
            \epsilon                        & \text{if } r = c,\\
            \emptyset                       & \text{if } r \in \Sigma \land r \neq c,\\
            D_{c v}(s) + D_c(t)                 & \text{if } r = s + t,\\
            D_c(s) \cdot t                  & \text{if } r = s \cdot t \land \epsilon \not\in \Lang{s},\\
            (D_c(s) \cdot t) + D_c(t)       & \text{if } r = s \cdot t \land \epsilon \in \Lang{s}.
        \end{cases}
    \end{align}
\end{definition}

Especially the last rule provides potential for infinitely growing terms.
Since it is unpleasant to implement and use algorithms which do not terminate,
these growing terms have to be taken care of.
This is done by replacing $\cdot$ and $+$ by the operations $\oplus$ and $\odot$
which are defined as follows:

\begin{definition}
    The operators $\oplus$ and $\odot$ perform simplifications according to axioms of Kleene algebra.
    Additionally, they sort the terms according to some total order $\preceq$ on regular expressions.

    \begin{align}
        \emptyset \odot \_     &\rightarrow \emptyset \\
        \_ \odot \emptyset     &\rightarrow \emptyset \\
        \epsilon \odot r       &\rightarrow r \\
        r \odot \epsilon       &\rightarrow r \\
        (r \cdot s) \odot t    &\rightarrow r \cdot (s \odot t) \\
        \text{else } r \odot s &\rightarrow r \cdot s
    \end{align}

    \begin{align}
        \emptyset \oplus r &\rightarrow r \\
        r \oplus \emptyset &\rightarrow r \\
        (r + s) \oplus t   &\rightarrow r \oplus (s \oplus t) \\
        r \oplus (s + t)   &\rightarrow
        \begin{cases}
            s + t            & \text{if } r = s \\
            r + (s + t)      & \text{if } r \preceq s \\
            s + (r \oplus t) & \text{otherwise}.
        \end{cases}
    \end{align}
\end{definition}

\begin{definition}
    The derivative can be extended to words by an inductive definition:

    \begin{align}
        \label{def:derivative_wrt_words}
        \Lang{D_v(r)} &\coloneqq \{ u \mid v u \in \Lang{r} \}
    \end{align}
\end{definition}

\begin{theorem}
    The derivative of a regular expression $r$ w.r.t. a word $w$ can be calculated with the following algorithm:

    \begin{align}
        D_\epsilon(r) &\rightarrow r \\
        \forall a \in \Sigma, w \in \Sigma^\ast: D_{a w}(r) &\rightarrow D_w(D_a(r))
    \end{align}
\end{theorem}

\begin{proof}
    We have to prove that both rules compute the right language.
    The former is trivially shown because it reduces to the same regular expression.

    For the latter, first we use the definition of $\Lang{D_w(r)}$ in~\ref{def:derivative_wrt_words}.
    By the definition of the derivative w.r.t. single characters,
    we know that iff $w~v~\in~\Lang{D_a(r)}$, then $a w v \in \Lang{r}$.
    Therefore:
    \begin{align}
        \Lang{D_w(r)}
            = \{ v \mid w v \in \Lang{D_a(r)} \}
            = \{ v \mid a w v \in \Lang{r} \}
            = \Lang{D_{a w}(r)}
    \end{align}
\end{proof}

\begin{theorem}
    A word $w$ is part of the language represented by a regular expression $r$ iff
    the language of the derivative of $r$ w.r.t. $w$ contains the empty set:

    \begin{align}
        w \in \Lang{r} \Leftrightarrow \epsilon \in \Lang{D_w(r)}
    \end{align}
\end{theorem}

\begin{proof}
    \begin{align}
        w \in \Lang{r} \Leftrightarrow w \epsilon \in \Lang{r} \Leftrightarrow \epsilon \in \Lang{D_w(r)}
    \end{align}

    The last step follows from~\ref{def:derivative_wrt_words}
\end{proof}

\subsection{Equivalence of Finite Automata and Regular Expressions}

\section{Automata Equivalence and Inclusion}

\subsection{Automata Equivalence}

\subsection{Hopcroft and Karp's Algorithm}

\subsection{Exploitation of Closure Properties}

\subsection{Antichain Method}
